# üß† NeuroServe ‚Äì GPU/CPU FastAPI AI Server

[![Python](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-Framework-green)](https://fastapi.tiangolo.com)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![CI (Linux)](https://github.com/TamerOnLine/NeuroServe/actions/workflows/ci-linux.yml/badge.svg)](https://github.com/TamerOnLine/NeuroServe/actions/workflows/ci-linux.yml)
[![CI (macOS)](https://github.com/TamerOnLine/NeuroServe/actions/workflows/ci-macos.yml/badge.svg)](https://github.com/TamerOnLine/NeuroServe/actions/workflows/ci-macos.yml)
[![CI (Windows)](https://github.com/TamerOnLine/NeuroServe/actions/workflows/ci-windows.yml/badge.svg)](https://github.com/TamerOnLine/NeuroServe/actions/workflows/ci-windows.yml)
[![GPU CI (Windows self-hosted)](https://github.com/TamerOnLine/NeuroServe/actions/workflows/gpu-ci.yml/badge.svg)](https://github.com/TamerOnLine/NeuroServe/actions/workflows/gpu-ci.yml)


A lightweight **REST API server** powered by **FastAPI** & **PyTorch**.  
It runs seamlessly on **GPU (CUDA)** if available, and safely falls back to **CPU**.  

üöÄ Includes a demo model, performance probes, a **web control panel**, and an extendable **Plugin System** for real AI models.

---

## ‚ú® Features
- ‚úÖ Auto-selects **GPU or CPU** at runtime (`DEVICE` in `.env`).
- ‚úÖ Clean **FastAPI** endpoints with Swagger UI (`/docs`) and ReDoc (`/redoc`).
- ‚úÖ Interactive **Control Panel** (`/ui`) & **Model Size Calculator** (`/tools/model-size`).
- ‚úÖ Example **TinyNet** model + benchmarks (`/matmul`, `/infer`).
- ‚úÖ Extensible **Plugin System** with ready-to-use AI models.
- ‚úÖ Works on **Windows/Linux/macOS** (CPU) & **CUDA** (NVIDIA GPUs).

---

## üìÇ Project Structure
```
app/
  main.py           # FastAPI app & endpoints
  runtime.py        # device selection, CUDA info, warmup
  toy_model.py      # TinyNet demo model
  plugins/          # Modular plugins (bart, clip, resnet18, ner, etc.)
  templates/        # HTML templates for UI
scripts/
  install_torch.py  # Auto-installs correct PyTorch (CPU/GPU)
  test_api.py       # Quick client to test endpoints
requirements.txt
README.md
```

---

## ‚ö° Quickstart

### 1. Setup Environment
**Windows (PowerShell)**:
```powershell
py -3.12 -m venv .venv
.\.venv\Scripts\Activate.ps1
```

**Linux/macOS**:
```bash
python3.12 -m venv .venv
source .venv/bin/activate
```

### 2. Install Dependencies
```bash
pip install -r requirements.txt
python -m scripts.install_torch
```

### 3. Run the Server
```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

Open in browser:
- **Swagger UI** ‚Üí http://localhost:8000/docs  
- **Control Panel** ‚Üí http://localhost:8000/ui  
- **Plugin Console** ‚Üí http://localhost:8000/plugins/ui  
- **Infer Client** ‚Üí http://localhost:8000/infer-client  

---

## ‚öôÔ∏è Configuration (`.env`)
```ini
# Prefer the first CUDA GPU if available
DEVICE=cuda:0

# Force CPU mode (override)
# DEVICE=cpu

# Warmup matrix size (for benchmarks)
WARMUP_MATMUL_SIZE=1024
```

---

## üîå API Endpoints

| Method | Path                | Description                      |
|--------|---------------------|----------------------------------|
| GET    | `/health`           | Health check                     |
| GET    | `/cuda`             | CUDA / device info               |
| GET    | `/env`              | Environment summary              |
| GET    | `/env/full`         | Full environment + GPU list      |
| GET    | `/env/system`       | OS/CPU/RAM system info           |
| POST   | `/matmul`           | Matrix multiply benchmark        |
| POST   | `/infer`            | TinyNet inference                |
| POST   | `/inference`        | Generic plugin inference         |
| GET    | `/plugins`          | List available plugins           |
| GET    | `/ui`               | Interactive control panel        |
| GET    | `/tools/model-size` | Model size calculator (UI)       |

---

## üß© Plugins
NeuroServe uses a **modular plugin system** under `app/plugins/`.

Available plugins:
- **bart** ‚Üí Text summarization (`facebook/bart-large-cnn`)
- **clip** ‚Üí Text ‚Üî Image embeddings & similarity
- **distilbert** ‚Üí Sentiment classification
- **resnet18** ‚Üí Image classification (ImageNet)
- **ner** ‚Üí Named Entity Recognition
- **tinyllama** ‚Üí Lightweight text generation
- **translator / translator_m2m** ‚Üí Translation
- **pdf_reader** ‚Üí Extract text from PDFs
- **dummy** ‚Üí Ping test
- **dichfoto_proxy** ‚Üí Forwarding proxy

üîß **Build your own Plugin (5 min)**
```python
from app.plugins.base import AIPlugin

class Plugin(AIPlugin):
    tasks = ["hello"]

    def load(self):
        print("[plugin] hello ready")

    def infer(self, payload):
        name = payload.get("name", "world")
        return {"task": "hello", "message": f"Hello, {name}!"}
```
Add it in `app/plugins/hello/` with `manifest.json`.

---

## üñ•Ô∏è Example Requests

**Matrix Multiply**
```bash
curl -X POST http://localhost:8000/matmul   -H "Content-Type: application/json"   -d '{"n": 2048}'
```

**BART Summarization**
```bash
curl -X POST http://localhost:8000/inference   -H "Content-Type: application/json"   -d '{"provider":"bart","task":"summarize","text":"Deep learning is a subfield..."}'
```

**NER Entity Extraction**
```bash
curl -X POST http://localhost:8000/inference   -H "Content-Type: application/json"   -d '{"provider":"ner","task":"extract-entities","text":"Barack Obama was born in Hawaii."}'
```

---

## üõ†Ô∏è Troubleshooting
- **Torch import error** ‚Üí Ensure Python 3.12 + rerun `python -m scripts.install_torch`.
- **No GPU detected** ‚Üí Falls back to CPU. Force with `DEVICE=cpu`.
- **CUDA mismatch** ‚Üí Reinstall torch with matching CUDA runtime.
- **Out of Memory (OOM)** ‚Üí Reduce `max_length` or use CPU mode.
- **Windows Execution Policy** ‚Üí  
  ```powershell
  Set-ExecutionPolicy -Scope CurrentUser RemoteSigned
  ```

---

## üìç Roadmap
- [ ] File upload endpoints (images/text).
- [ ] Docker images (CPU & GPU).
- [ ] Extended plugin demo UI.
- [ ] CI/CD with pre-commit hooks & GitHub Actions.
- [x] Real AI plugins (BART, CLIP, ResNet, DistilBERT, NER, etc.).

---

## üìú License
MIT ¬© 2025 [TamerOnLine](https://github.com/TamerOnLine)
