# ğŸš€ NeuroServe -- GPU-Ready FastAPI AI Server

[![Python](https://img.shields.io/badge/Python-3.12%2B-blue.svg)](https://www.python.org/)\
[![FastAPI](https://img.shields.io/badge/FastAPI-0.116.1-009688.svg)](https://fastapi.tiangolo.com/)\
[![PyTorch](https://img.shields.io/badge/PyTorch-2.6.0%2B-ee4c2c.svg)](https://pytorch.org/)\
[![Tests](https://github.com/USERNAME/REPO/actions/workflows/tests.yml/badge.svg)](https://github.com/USERNAME/REPO/actions)\
[![License:
MIT](https://img.shields.io/badge/License-MIT-green.svg)](./LICENSE)

------------------------------------------------------------------------

## ğŸ“– Overview

**NeuroServe** is an **AI Inference Server** built on
[FastAPI](https://fastapi.tiangolo.com/) designed to run seamlessly on
**GPU / CPU / ROCm / macOS MPS**.\
It provides:

-   ğŸŒ **Ready-to-use REST API** with Swagger UI & ReDoc\
-   âš¡ **PyTorch integration** (CUDA / ROCm / CPU / MPS)\
-   ğŸ§  **Prefetch scripts** for Hugging Face models (BART, DistilBERT,
    mT5, Whisper, TinyLlama, ResNet18...)\
-   ğŸ”§ **install_torch.py** script for automatic PyTorch installation\
-   ğŸ“Š Runtime utilities to inspect GPU & benchmark performance (CUDA
    info + warmup)\
-   ğŸ§© Example TinyNet model & **MLP memory size calculator**\
-   ğŸ“š Unified `unify_response` utility for consistent model/API outputs

------------------------------------------------------------------------

## ğŸ“‚ Project Structure

    gpu-server/
    â”œâ”€â”€ app/                # Core server (FastAPI + Runtime + Models)
    â”‚   â”œâ”€â”€ main.py         # FastAPI entrypoint
    â”‚   â”œâ”€â”€ runtime.py      # Device & CUDA management
    â”‚   â”œâ”€â”€ toy_model.py    # Simple PyTorch model
    â”‚   â””â”€â”€ utils/          # Utilities (unified responses)
    â”œâ”€â”€ scripts/            # Helper scripts
    â”‚   â”œâ”€â”€ install_torch.py  # Auto PyTorch installer
    â”‚   â”œâ”€â”€ prefetch_models.py # Download Hugging Face models
    â”‚   â””â”€â”€ conftest.py       # PyTest fixtures
    â”œâ”€â”€ docs/               # Docs & licenses
    â”œâ”€â”€ requirements.txt    # Core dependencies
    â”œâ”€â”€ requirements-dev.txt# Dev/test dependencies
    â”œâ”€â”€ pyproject.toml      # Ruff + PyTest + Coverage configs
    â””â”€â”€ LICENSE             # MIT License

------------------------------------------------------------------------

## âš™ï¸ Installation

### 1. Clone the repo

``` bash
git clone https://github.com/USERNAME/gpu-server.git
cd gpu-server
```

### 2. Create virtual environment

``` bash
python -m venv .venv
source .venv/bin/activate   # Linux/macOS
.venv\Scripts\activate    # Windows
```

### 3. Install dependencies

``` bash
pip install -r requirements.txt
```

### 4. (Optional) Auto-install PyTorch

``` bash
python -m scripts.install_torch --gpu   # or --cpu / --rocm
```

### 5. Run the server

``` bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

------------------------------------------------------------------------

## ğŸ–¥ï¸ Usage

Once running, open your browser:

-   <http://localhost:8000/> â†’ Home\
-   <http://localhost:8000/docs> â†’ Swagger UI\
-   <http://localhost:8000/redoc> â†’ ReDoc\
-   <http://localhost:8000/health> â†’ Health check
- http://localhost:8000/env

Example request:

``` bash
curl http://localhost:8000/health
# {"status": "ok"}
```

------------------------------------------------------------------------

## ğŸ§ª Development & Testing

Install dev requirements:

``` bash
pip install -r requirements-dev.txt
pre-commit install
```

Run tests:

``` bash
pytest
```

------------------------------------------------------------------------

## ğŸ“Š Prefetch Models

To download supported models into `models_cache/`:

``` bash
python -m scripts.prefetch_models
```

Included models: - ğŸ“„ NLP: BART, DistilBERT, mT5, TinyLlama\
- ğŸ™ï¸ Speech: Whisper\
- ğŸ–¼ï¸ Vision: ResNet18

------------------------------------------------------------------------

## ğŸ¤ Contributing

Contributions are welcome!\
- Open **Issues** for ideas or bugs.\
- Use **Pull Requests** for changes.\
- Follow code style (Ruff + pre-commit).

------------------------------------------------------------------------

## ğŸ“œ License

This project is licensed under the **MIT License** -- see
[LICENSE](./LICENSE).\
\> Some models have their own licenses -- see
[docs/LICENSES.md](docs/LICENSES.md).
