name: CI (GPU)

on:
  push:
    branches: [ main ]
  pull_request:
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.head_ref || github.ref }}
  cancel-in-progress: true

jobs:
  # ===== CUDA on Linux (self-hosted) =====
  cuda_linux:
    name: CUDA • Linux self-hosted
    runs-on: [self-hosted, linux, gpu, cuda]
    timeout-minutes: 30
    env:
      PYTHONPATH: ${{ github.workspace }}
    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: pip

      - name: Install deps (incl. torch via helper)
        shell: bash
        run: |
          python -m pip install -U pip
          pip install -r requirements.txt
          if [ -f requirements-dev.txt ]; then pip install -r requirements-dev.txt; fi
          python -m scripts.install_torch --gpu || true

      - name: Verify CUDA available
        shell: bash
        run: |
          python - << 'PY'
          import torch, sys
          print("torch:", torch.__version__, "cuda:", getattr(torch.version, "cuda", None))
          print("cuda available:", torch.cuda.is_available())
          sys.exit(0 if torch.cuda.is_available() else 1)
          PY

      - name: Pytest (gpu_cuda markers)
        env:
          DEVICE: cuda:0
        shell: bash
        run: |
          pytest -q -m "gpu_cuda" --maxfail=1

      - name: GPU smoke /health
        env:
          DEVICE: cuda:0
          APP_RELOAD: "false"
        shell: bash
        run: |
          uvicorn app.main:app --host 127.0.0.1 --port 8001 &
          pid=$!
          python - << 'PY'
          import time, urllib.request, sys
          for _ in range(30):
              try:
                  with urllib.request.urlopen('http://127.0.0.1:8001/health', timeout=1) as r:
                      print(r.read())
                      sys.exit(0)
              except Exception:
                  time.sleep(0.5)
          sys.exit(1)
          PY
                    kill $pid || true

  # ===== CUDA on Windows (self-hosted) =====
  cuda_windows:
    name: CUDA • Windows self-hosted
    runs-on: [self-hosted, windows, gpu, cuda]
    timeout-minutes: 30
    env:
      PYTHONPATH: ${{ github.workspace }}
    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: pip

      - name: Install deps
        shell: powershell
        run: |
          python -m pip install -U pip
          pip install -r requirements.txt
          if (Test-Path requirements-dev.txt) { pip install -r requirements-dev.txt }
          python -m scripts.install_torch --gpu

      - name: Verify CUDA available
        shell: powershell
        run: |
          python - << 'PY'
          import torch, sys
          print("torch:", torch.__version__, "cuda:", getattr(torch.version, "cuda", None))
          print("cuda available:", torch.cuda.is_available())
          sys.exit(0 if torch.cuda.is_available() else 1)
          PY

      - name: Pytest (gpu_cuda markers)
        env:
          DEVICE: cuda:0
        shell: powershell
        run: |
          pytest -q -m "gpu_cuda" --maxfail=1

      - name: GPU smoke /health
        env:
          DEVICE: cuda:0
          APP_RELOAD: "false"
        shell: powershell
        run: |
          Start-Process -FilePath uvicorn -ArgumentList "app.main:app --host 127.0.0.1 --port 8002" -PassThru | Set-Variable proc
          python - << 'PY'
          import time, urllib.request, sys
          for _ in range(30):
              try:
                  with urllib.request.urlopen('http://127.0.0.1:8002/health', timeout=1) as r:
                      print(r.read())
                      sys.exit(0)
              except Exception:
                  time.sleep(0.5)
          sys.exit(1)
          PY
                    if ($proc) { Stop-Process -Id $proc.Id -Force }

  # ===== MPS on macOS (GitHub-hosted Apple Silicon) =====
  mps_macos:
    name: MPS • macOS (Apple Silicon)
    runs-on: macos-14
    timeout-minutes: 25
    env:
      PYTHONPATH: ${{ github.workspace }}
    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: pip

      - name: Install deps
        shell: bash
        run: |
          python -m pip install -U pip
          pip install -r requirements.txt
          if [ -f requirements-dev.txt ]; then pip install -r requirements-dev.txt; fi

      - name: Verify MPS available
        shell: bash
        run: |
          python - << 'PY'
          import torch, sys
          avail = hasattr(torch.backends, "mps") and torch.backends.mps.is_available()
          print("torch:", torch.__version__)
          print("mps available:", avail)
          sys.exit(0 if avail else 1)
          PY

      - name: Pytest (gpu_mps markers)
        env:
          DEVICE: mps
        shell: bash
        run: |
          pytest -q -m "gpu_mps" --maxfail=1
