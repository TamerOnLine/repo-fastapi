name: CI (Windows Self-Hosted + GPU)

on:
  push:
    branches: [ main ]
    paths:
      - "**.py"
      - "pyproject.toml"
      - "requirements*.txt"
      - ".github/workflows/ci-gpu.yml"
      - "app/**"
      - "tests/**"
  pull_request:
    branches: [ main ]
  workflow_dispatch:

permissions:
  contents: read

concurrency:
  group: ci-${{ github.ref }}-${{ github.workflow }}
  cancel-in-progress: true

defaults:
  run:
    shell: powershell

env:
  PIP_DISABLE_PIP_VERSION_CHECK: "1"
  PIP_NO_PYTHON_VERSION_WARNING: "1"
  PYTHONDONTWRITEBYTECODE: "1"

jobs:
  lint:
    name: Lint (ruff/flake + basic checks)
    runs-on: [self-hosted, Windows, X64]
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Bootstrap cache/env vars
        id: boot
        run: |
          $cacheDir = Join-Path $env:RUNNER_TEMP 'pip-cache'
          "cache_dir=$cacheDir" | Out-File -FilePath $env:GITHUB_OUTPUT -Append
          "os=$env:RUNNER_OS"   | Out-File -FilePath $env:GITHUB_OUTPUT -Append

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ${{ steps.boot.outputs.cache_dir }}
          key: pip-${{ steps.boot.outputs.os }}-${{ hashFiles('**/requirements*.txt', 'pyproject.toml') }}
          restore-keys: |
            pip-${{ steps.boot.outputs.os }}-

      - name: Install tooling
        run: |
          python -m pip install -U pip wheel setuptools
          python -m pip install ruff flake8

      - name: Ruff check
        run: ruff check .

      - name: Flake8
        run: flake8 .

  tests-cpu:
    name: Tests (CPU)
    runs-on: [self-hosted, Windows, X64]
    needs: [lint]
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Bootstrap cache/env vars
        id: boot
        run: |
          $cacheDir = Join-Path $env:RUNNER_TEMP 'pip-cache'
          "cache_dir=$cacheDir" | Out-File -FilePath $env:GITHUB_OUTPUT -Append
          "os=$env:RUNNER_OS"   | Out-File -FilePath $env:GITHUB_OUTPUT -Append

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ${{ steps.boot.outputs.cache_dir }}
          key: pip-${{ steps.boot.outputs.os }}-${{ hashFiles('**/requirements*.txt', 'pyproject.toml') }}
          restore-keys: |
            pip-${{ steps.boot.outputs.os }}-

      - name: Install deps
        run: |
          python -m pip install -U pip wheel setuptools
          if (Test-Path "requirements.txt") { pip install -r requirements.txt }
          if (Test-Path "requirements-dev.txt") { pip install -r requirements-dev.txt }
          if (Test-Path "pyproject.toml") { pip install -e . }

      - name: Print Python & Torch info (if present)
        continue-on-error: true
        run: |
          python -V
          $code = @'
          try:
              import torch, platform
              print("Torch:", torch.__version__)
              print("CUDA available:", torch.cuda.is_available())
              print("Device count:", torch.cuda.device_count() if torch.cuda.is_available() else 0)
          except Exception as e:
              print("Torch not installed:", e)
          '@
                    python -c $code

                - name: Run pytest (CPU-only)
                  env:
                    PYTEST_ADDOPTS: "-q"
                  run: |
                    mkdir -Force .\test-logs | Out-Null
                    pytest -q -m "not gpu and not gpu_cuda and not gpu_mps" --maxfail=1 --disable-warnings `
                          --log-cli-level=INFO `
                          2>&1 | Tee-Object -FilePath .\test-logs\pytest_cpu.txt

                - name: Upload CPU test logs
                  if: always()
                  uses: actions/upload-artifact@v4
                  with:
                    name: logs-cpu
                    path: test-logs/

            tests-gpu:
              name: Tests (GPU)
              runs-on: [self-hosted, Windows, X64]
              needs: [tests-cpu]
              steps:
                - name: Checkout
                  uses: actions/checkout@v4

                - name: Bootstrap cache/env vars
                  id: boot
                  run: |
                    $cacheDir = Join-Path $env:RUNNER_TEMP 'pip-cache'
                    "cache_dir=$cacheDir" | Out-File -FilePath $env:GITHUB_OUTPUT -Append
                    "os=$env:RUNNER_OS"   | Out-File -FilePath $env:GITHUB_OUTPUT -Append

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ${{ steps.boot.outputs.cache_dir }}
          key: pip-${{ steps.boot.outputs.os }}-${{ hashFiles('**/requirements*.txt', 'pyproject.toml') }}
          restore-keys: |
            pip-${{ steps.boot.outputs.os }}-

      - name: Install deps (incl. torch from requirements*)
        run: |
          python -m pip install -U pip wheel setuptools
          if (Test-Path "requirements.txt") { pip install -r requirements.txt }
          if (Test-Path "requirements-dev.txt") { pip install -r requirements-dev.txt }
          if (Test-Path "pyproject.toml") { pip install -e . }

      - name: Show NVIDIA GPU
        id: nvsmi
        continue-on-error: true
        run: |
          $exists = Get-Command nvidia-smi -ErrorAction SilentlyContinue
          if ($null -eq $exists) {
            Write-Host "nvidia-smi not found"
            echo "has_gpu=false" >> $env:GITHUB_OUTPUT
          } else {
            nvidia-smi
            echo "has_gpu=true" >> $env:GITHUB_OUTPUT
          }

      - name: Torch CUDA availability
        id: torchcheck
        continue-on-error: true
        run: |
          $code = @'
          try:
              import torch
              print("Torch:", torch.__version__)
              print("CUDA available:", torch.cuda.is_available())
              print("CUDA devices:", torch.cuda.device_count() if torch.cuda.is_available() else 0)
          except Exception as e:
              print("Torch not installed:", e)
          '@
                    python -c $code

                - name: Run pytest (GPU markers)
                  if: steps.nvsmi.outputs.has_gpu == 'true'
                  env:
                    PYTEST_ADDOPTS: "-q"
                  run: |
                    mkdir -Force .\test-logs | Out-Null
                    pytest -q -m "gpu or gpu_cuda or gpu_mps" --maxfail=1 --disable-warnings `
                          --log-cli-level=INFO `
                          2>&1 | Tee-Object -FilePath .\test-logs\pytest_gpu.txt

                - name: Upload GPU test logs
                  if: always()
                  uses: actions/upload-artifact@v4
                  with:
                    name: logs-gpu
                    path: test-logs/
